{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Smile Detection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing open cv library\n",
    "import cv2"
   ]
  },
  {
   "source": [
    "*OpenCV* supports **haar cascade** based object detection.\n",
    "\n",
    "Haar Cascades are machine learning based classifiers that calculate different features like edges, lines etc. in the image.\n",
    "\n",
    "Trained classifiers for different objects like faces,eyes etc are available in the OpenCV Github repo, you can also train your own haar cascade for any object.\n",
    "\n",
    "For Face detection model we are using \"haarcascade_smile.xml\""
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')"
   ]
  },
  {
   "source": [
    "## Smile detection (Passing image as an input)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for displaying image\n",
    "def showImage(img):\n",
    "    cv2.imshow('Image',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading an image\n",
    "image = cv2.imread(\"smile.jpg\")\n",
    "image = cv2.resize(image, (590,750))\n",
    "showImage(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detecting face as well as smile :)\n",
    "face = face_cascade.detectMultiScale(image, 1.4, 3)\n",
    "\n",
    "for(x, y, w, h) in face:\n",
    "    cv2.rectangle(image, (x, y), (x+w, y+h), (255,0,0), 2)\n",
    "    roi_frame = image[y:y+h, x:x+w]\n",
    "\n",
    "    smile = smile_cascade.detectMultiScale(roi_frame, 1.8, 3)\n",
    "\n",
    "    for (ex, ey, ew, eh) in smile:\n",
    "        cv2.rectangle(roi_frame, (ex,ey), (ex+ew, ey+eh), (0,0,255), 2)\n",
    "showImage(image)"
   ]
  },
  {
   "source": [
    "## Face Detection (real time video capturing)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are converting color image to gray image because haarcascade works better with it..!!\n",
    "def detectSmile(gray_image, color_image):\n",
    "    face = face_cascade.detectMultiScale(gray_image, 1.3, 5)\n",
    "\n",
    "    for(x, y, w, h) in face:\n",
    "        cv2.rectangle(color_image, (x, y), (x+w, y+h), (0,255,0), 2)\n",
    "\n",
    "        roi_frame = color_image[y:y+h, x:x+w]\n",
    "        roi_gray = gray_image[y:y+h, x:x+w]\n",
    "\n",
    "        smile = smile_cascade.detectMultiScale(roi_gray, 1.8, 13)\n",
    "\n",
    "        for (sx, sy, sw, sh) in smile:\n",
    "            cv2.rectangle(roi_frame, (sx,sy), (sx+sw, sy+sh), (0,0,255), 2)\n",
    "\n",
    "    return color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\ndef detectSMile(gray,frame):\\n    face = face_cascade.detectMultiScale(gray, 1.1, 2)\\n\\n    for(x, y, w, h) in face:\\n        cv2.rectangle(frame, (x, y), (x+w, y+h), (255,0,0), 2)\\n\\n        roi_frame = frame[y:y+h, x:x+w]\\n        roi_gray = gray[y:y+h, x:x+w]\\n\\n        smile = smile_cascade.detectMultiScale(roi_gray, 1.8, 10)\\n        for (sx, sy, sw, sh) in smile:\\n            cv2.rectangle(roi_frame, (sx,sy), (sx+sw, sy+sh), (0,0,255), 2)\\n    return frame\\n    '"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "\"\"\"\n",
    "def detectSMile(gray,frame):\n",
    "    face = face_cascade.detectMultiScale(gray, 1.1, 2)\n",
    "\n",
    "    for(x, y, w, h) in face:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255,0,0), 2)\n",
    "\n",
    "        roi_frame = frame[y:y+h, x:x+w]\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        smile = smile_cascade.detectMultiScale(roi_gray, 1.8, 10)\n",
    "        for (sx, sy, sw, sh) in smile:\n",
    "            cv2.rectangle(roi_frame, (sx,sy), (sx+sw, sy+sh), (0,0,255), 2)\n",
    "    return frame\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    _,frame = video_capture.read()\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    detect_face = detectSmile(gray,frame)\n",
    "    cv2.imshow(\"video\", detect_face)\n",
    "    if cv2.waitKey(1) & 0XFF==ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}